<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MMLU-ProX: A Multi-Lingual Benchmark for Advanced LLM Evaluation</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        h2 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
        }
        .header {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }
        .header img {
            height: 60px;
            margin-right: 15px;
        }
        .buttons {
            margin: 20px 0;
        }
        .button {
            display: inline-block;
            padding: 8px 16px;
            margin-right: 10px;
            background-color: #f6f8fa;
            border: 1px solid rgba(27, 31, 35, 0.15);
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
            line-height: 20px;
            text-decoration: none;
            color: #24292e;
        }
        .primary-button {
            background-color: #2ea44f;
            color: #fff;
            border-color: rgba(27, 31, 35, 0.15);
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            padding: 8px 13px;
            border: 1px solid #dfe2e5;
            text-align: left;
        }
        th {
            background-color: #f6f8fa;
        }
        .highlight {
            font-weight: bold;
        }
        .authors {
            margin-bottom: 20px;
        }
        .affiliations {
            margin-bottom: 30px;
            color: #586069;
        }
        .language-icon {
            height: 20px;
            vertical-align: middle;
            margin-right: 5px;
        }
        .chart {
            max-width: 100%;
            margin: 30px 0;
            border: 1px solid #dfe2e5;
            border-radius: 6px;
            padding: 15px;
        }
    </style>
</head>
<body>
    <h1>MMLU-ProX: A Multi-Lingual Benchmark for Advanced Large Language Model Evaluation</h1>

    <div class="authors">
        Weihao Xuan<sup>1</sup>, Rui Yang<sup>2</sup>, Heli Qi<sup>3</sup>, Qingcheng Zeng<sup>4</sup>, Yunze Xiao<sup>5</sup>,
        Yun Xing<sup>6</sup>, Junjue Wang<sup>1</sup>, Huitao Li<sup>2</sup>, Xin Li<sup>2</sup>, Edison Marrese-Taylor<sup>1</sup>,
        Nan Liu<sup>2</sup>, Qingyu Chen<sup>7</sup>, Douglas Teodoro<sup>8</sup>,
        Shijian Lu<sup>6</sup>, Yusuke Iwasawa<sup>1</sup>, Yutaka Matsuo<sup>1</sup>, Irene Li<sup>1</sup>
    </div>

    <div class="affiliations">
        <sup>1</sup>The University of Tokyo, <sup>2</sup>NUS-Duke Medical School, <sup>3</sup>Waseda University<br>
        <sup>4</sup>Northwestern University, <sup>5</sup>Carnegie Mellon University<br>
        <sup>6</sup>Nanyang Technological University, <sup>7</sup>Yale University, <sup>8</sup>University of Geneva<br>
        weihaoxuan@g.ecc.u-tokyo.ac.jp, ireneli@ds.itc.u-tokyo.ac.jp
    </div>

    <div class="buttons">
        <a href="#" class="button primary-button">Paper(Coming Soon)</a>
        <a href="https://github.com/weihao1115/MMLU-ProX" class="button primary-button">Code</a>
        <a href="https://huggingface.co/datasets/li-lab/MMLU-ProX" class="button primary-button">Dataset</a>
        <a href="#" class="button primary-button">Leaderboard (Coming Soon)</a>
    </div>

    <h2>Abstract</h2>
    <p>
        Traditional benchmarks struggle to evaluate increasingly sophisticated language models in multilingual and culturally diverse contexts.
        To address this gap, we introduce MMLU-ProX, a multilingual benchmark spanning 13 typologically diverse languages.
        Building on the challenging reasoning-focused design of MMLU-Pro, our framework employs a semi-automatic translation process:
        translations generated by state-of-the-art large language models (LLMs) are rigorously evaluated by lingual experts to ensure
        conceptual accuracy, terminological consistency, and cultural relevance. We comprehensively evaluate 25 state-of-the-art LLMs using
        chain-of-thought (CoT) and direct answer prompting strategies, analyzing their performance across lingual and cultural boundaries.
        <b>MMLU-ProX is an ongoing project; we are expanding our benchmark by incorporating additional languages and evaluating more language
        models to provide a more comprehensive assessment of multilingual capabilities.</b>
    </p>

    <h2>Languages Covered (13)</h2>
    <div style="display: flex; flex-wrap: wrap;">
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡¬ðŸ‡§ English (EN)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡¨ðŸ‡³ Chinese (ZH)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡¯ðŸ‡µ Japanese (JA)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡°ðŸ‡· Korean (KO)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡«ðŸ‡· French (FR)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡©ðŸ‡ª German (DE)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡ªðŸ‡¸ Spanish (ES)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡µðŸ‡¹ Portuguese (PT)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡¸ðŸ‡¦ Arabic (AR)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡¹ðŸ‡­ Thai (TH)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡®ðŸ‡³ Hindi (HI)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡§ðŸ‡© Bengali (BN)</span>
        </div>
        <div style="margin: 10px; text-align: center;">
            <span>ðŸ‡°ðŸ‡ª Swahili (SW)</span>
        </div>
    </div>

    <h2>Features</h2>
    <ul>
        <li><strong>Reasoning-Focused Design:</strong> Built upon MMLU-Pro, maintaining its challenging nature and reasoning focus</li>
        <li><strong>Extensive Language Coverage:</strong> 13 typologically diverse languages from various language families</li>
        <li><strong>High-Quality Translations:</strong> Semi-automatic translation process with expert verification</li>
        <li><strong>Comprehensive Evaluation:</strong> Tested on 25 state-of-the-art LLMs with multiple prompting strategies</li>
        <li><strong>Open Source:</strong> Dataset and evaluation code available to the research community</li>
    </ul>

    <h2>Performance Results (5-shot CoT)</h2>
    <div class="chart">
        <table>
            <tr>
                <th>Models</th>
                <th>Overall</th>
                <th>EN</th>
                <th>ZH</th>
                <th>JA</th>
                <th>KO</th>
                <th>FR</th>
                <th>DE</th>
                <th>ES</th>
                <th>PT</th>
                <th>AR</th>
                <th>TH</th>
                <th>HI</th>
                <th>BN</th>
                <th>SW</th>
            </tr>
            <tr>
                <td>Qwen2.5-72B</td>
                <td>62.0</td>
                <td>70.3</td>
                <td>65.9</td>
                <td>63.4</td>
                <td>62.1</td>
                <td>67.1</td>
                <td>65.9</td>
                <td>66.5</td>
                <td>66.6</td>
                <td>62.1</td>
                <td>60.1</td>
                <td>58.0</td>
                <td>57.6</td>
                <td>40.1</td>
            </tr>
            <tr>
                <td>QwQ-32B</td>
                <td>60.2</td>
                <td>70.7</td>
                <td>65.7</td>
                <td>62.8</td>
                <td>62.6</td>
                <td>67.4</td>
                <td>63.0</td>
                <td>66.7</td>
                <td>65.3</td>
                <td>62.0</td>
                <td>61.7</td>
                <td>49.1</td>
                <td>52.7</td>
                <td>32.8</td>
            </tr>
            <tr>
                <td>Llama3.1-405B</td>
                <td>60.1</td>
                <td>68.8</td>
                <td>62.5</td>
                <td>59.9</td>
                <td>51.6</td>
                <td>65.1</td>
                <td>64.4</td>
                <td>64.9</td>
                <td>64.3</td>
                <td>55.4</td>
                <td>59.1</td>
                <td>58.0</td>
                <td>54.9</td>
                <td>52.1</td>
            </tr>
            <tr>
                <td>Llama3.3-70B</td>
                <td>57.1</td>
                <td>65.7</td>
                <td>58.4</td>
                <td>57.0</td>
                <td>54.5</td>
                <td>62.1</td>
                <td>59.8</td>
                <td>61.5</td>
                <td>61.4</td>
                <td>51.0</td>
                <td>56.0</td>
                <td>55.4</td>
                <td>50.1</td>
                <td>49.0</td>
            </tr>
            <tr>
                <td>Phi4-14B</td>
                <td>55.2</td>
                <td>63.7</td>
                <td>58.8</td>
                <td>54.7</td>
                <td>54.5</td>
                <td>62.9</td>
                <td>62.2</td>
                <td>63.0</td>
                <td>62.5</td>
                <td>54.6</td>
                <td>49.9</td>
                <td>49.4</td>
                <td>43.7</td>
                <td>37.9</td>
            </tr>
        </table>
    </div>

    <h2>Key Findings</h2>
    <ul>
        <li>Consistent performance degradation from high-resource to low-resource languages across all models</li>
        <li>Larger models consistently outperform smaller counterparts within the same family</li>
        <li>Different prompting strategies show varying effectiveness depending on language resource levels</li>
        <li>Reasoning-enhanced training yields inconsistent benefits across different languages</li>
    </ul>

    <h2>Citation</h2>
    <pre style="background-color: #f6f8fa; padding: 16px; border-radius: 6px; overflow: auto;">
        Coming soon
    </pre>

    <h2>Acknowledgments</h2>
    <p>
        This research was supported by several organizations. The Japan Society for the JSPS KAKENHI
        provided funding under Grant Number 24K20832. Additional support was received from JST ActX,
        Grant Number JPMJAX24CU. We also acknowledge the contributions of NVIDIA through their
        Academic Grant Program and Google via the Gemma Academic Program.
    </p>
</body>
</html>